experiment_name: dynamic_prediction
seed: 12  # Add seed for reproducibility

data:
  preprocessed_dir: ./data/preprocessed/ventilation_seed12
  numerical_columns:
    - age
    - weight
    - PIM
    - MAP
    - RR(measured)
    - etCO2
    - temp
    - HR
    - SpO2
    - systolicBP
    - meanBP
    - diastolicBP
    - pH
    - PCO2
    - baseExcess
    - lactate
    - HCO3
    - WBC
    - Neutrophil
    - Hb
    - fluidBalance
    - FiO2
    - PIP
    - RR(set)
    - PEEP(set)
    - inspTime
    - PS
    - TVbyWeight
    - hoursVentilated
    # - SFRatio
    # - RRRatio
    # - IERatio
    # - deltaP
    # - mPower
  binary_columns:
    - gender
    - NMB
    - sedation
    - furosemide
    - vasoActive
    - steroid
    - ventMode_PC
    - ventMode_PS
    - diagnosis_cardiovascular
    - diagnosis_gastrointestinal
    - diagnosis_infection
    - diagnosis_neurological
    - diagnosis_others
    - diagnosis_respiratory
  target_column: successful_extubation_next_24h
  window_size: 1
  stride: 1

dataset:
  module: scripts.experiments.dynamic_prediction.main
  class: DynamicPredictionDataset

model:
  name: base_model
  class: BaseModel
  params:
    encoder:
      type: LSTM
      input_dim: 43
      hidden_dim: 64
      num_layers: 2
      dropout: 0.6
      bidirectional: false
      batch_first: true
    classifier:
      input_dim: 64
      output_dims: 
        - 64
        - 1
      dropouts:
        '0': 0.6
        # '1': 0.3
      activation: 
        type: leakyrelu
      out_activation: 
        type: sigmoid

loss:
  name: BCELoss

metrics:
  precision:
    module: torchmetrics.classification
    class: BinaryPrecision
    target_dtype: int
  auroc:
    module: torchmetrics.classification
    class: BinaryAUROC
    target_dtype: int
  auprc:
    module: torchmetrics.classification
    class: BinaryAveragePrecision
    target_dtype: int
  # confusion_matrix:
  #   module: torchmetrics.classification
  #   class: BinaryConfusionMatrix
  #   params:
  #     normalize: 'true'
  #   target_dtype: int

optimizer:
  class: Adam
  params:
    lr: 0.0001
    weight_decay: 0.00001

training:
  max_epochs: 100
  early_stopping_patience: 5
  grad_clip_val: 1.0
  train_batch_size: 256
  val_batch_size: 256
  num_workers: 8

logging:
  base_dir: ./results
  log_every_n_steps: 1
  save_every_n_epochs: 1
  plot_every_n_epochs: 1